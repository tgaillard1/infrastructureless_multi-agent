# Copy as .env file and fill your values below
# Run ./update_dotenv_example.sh to update .env-example from your .env file.

# Choose Model Backend: 0 -> ML Dev, 1 -> Vertex
GOOGLE_GENAI_USE_VERTEXAI=1

# ML Dev backend config. Fill if using Ml Dev backend.
GOOGLE_API_KEY=YOUR_VALUE_HERE

# Vertex backend config
GOOGLE_CLOUD_PROJECT='YOUR_VALUE_HERE'
GOOGLE_CLOUD_LOCATION='YOUR_VALUE_HERE'

# SQLGen method
NL2SQL_METHOD="BASELINE" # BASELINE or CHASE

# Set up BigQuery Agent
BQ_COMPUTE_PROJECT_ID='YOUR_VALUE_HERE'
BQ_DATA_PROJECT_ID='YOUR_VALUE_HERE'
BQ_DATASET_ID='YOUR_VALUE_HERE'
BQ_PROJECT_ID='YOUR_VALUE_HERE'

# Set up RAG Corpus for BQML Agent
BQML_RAG_CORPUS_NAME='' # Leave this empty if no docs to provide

# Existing corpus in Vertex RAG Engine to be used by RAG agent
# e.g. projects/123/locations/us-central1/ragCorpora/456
RAG_CORPUS='' # Leave this empty if no docs to provide
# Staging bucket name for ADK agent deployment to Vertex AI Agent Engine (Shall respect this format gs://your-bucket-name)
STAGING_BUCKET='YOUR_VALUE_HERE'

# Agent Engine ID in the following format: projects/<PROJECT_NUMBER>/locations/us-central1/reasoningEngines/<AGENT_ENGINE_ID>
AGENT_ENGINE_ID='none'

# Set up Code Interpreter, if it exists. Else leave empty
CODE_INTERPRETER_EXTENSION_NAME='' # Either '' or 'projects/{GOOGLE_CLOUD_PROJECT}/locations/us-central1/extensions/{EXTENSION_ID}'

# Models used in Agents
ROOT_AGENT_MODEL='gemini-2.5-flash'
ANALYTICS_AGENT_MODEL='gemini-2.5-flash'
BIGQUERY_AGENT_MODEL='gemini-2.5-flash'
BASELINE_NL2SQL_MODEL='gemini-2.5-flash'
CHASE_NL2SQL_MODEL='gemini-2.5-flash'
BQML_AGENT_MODEL='gemini-2.5-flash'
RAG_AGENT_MODEL='gemini-2.5-flash'
